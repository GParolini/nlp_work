{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial source: https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03\n",
    "Source for the ATIS data set: https://www.kaggle.com/siddhadev/atis-dataset-from-ms-cntk/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEF: a TRANSFORMER is a network that applies attention mechanisms to gather information about the relevant context of a given word, and then encode that context in a vector that smartly represents the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEF: BERT (Bidirectional Encoder Representations from Transformers) is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a re- sult, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# load Pickle file \n",
    "def load_ds(fname, verbose=True):\n",
    "    with open(fname, 'rb') as stream:\n",
    "        ds,dicts = pickle.load(stream)\n",
    "    if verbose:\n",
    "      print('Done  loading: ', fname)\n",
    "      print('      samples: {:4d}'.format(len(ds['query'])))\n",
    "      print('   vocab_size: {:4d}'.format(len(dicts['token_ids'])))\n",
    "      print('   slot count: {:4d}'.format(len(dicts['slot_ids'])))\n",
    "      print(' intent count: {:4d}'.format(len(dicts['intent_ids'])))\n",
    "    return ds,dicts\n",
    "#load_ds(os.path.join(\"atis\",\"atis.train.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# convert Pickle file to arrays\n",
    "def load_atis(filename, add_start_end_token=False, verbose=True):\n",
    "    train_ds, dicts = load_ds(os.path.join(\"atis\",filename), verbose)\n",
    "    t2i, s2i, in2i = map(dicts.get, ['token_ids', 'slot_ids','intent_ids'])\n",
    "    i2t, i2s, i2in = map(lambda d: {d[k]:k for k in d.keys()}, [t2i,s2i,in2i])\n",
    "    query, slots, intent =  map(train_ds.get, ['query', 'slot_labels', 'intent_labels'])\n",
    "\n",
    "    if add_start_end_token:\n",
    "        i2s[178] = 'BOS'\n",
    "        i2s[179] = 'EOS'\n",
    "        s2i['BOS'] = 178\n",
    "        s2i['EOS'] = 179\n",
    "\n",
    "    input_tensor = []\n",
    "    target_tensor = []\n",
    "    query_data = []\n",
    "    intent_data = []\n",
    "    slot_data = []\n",
    "    to_show = np.random.randint(0, len(query)-1, 5)\n",
    "    for i in range(len(query)):\n",
    "        input_tensor.append(query[i])\n",
    "        slot_text = []\n",
    "        slot_vector = []\n",
    "        for j in range(len(query[i])):\n",
    "            slot_text.append(i2s[slots[i][j]])\n",
    "            slot_vector.append(slots[i][j])\n",
    "        if add_start_end_token:\n",
    "            slot_text[0] = 'BOS'\n",
    "            slot_vector[0] = 178\n",
    "            slot_text[-1] = 'EOS'\n",
    "            slot_vector[-1]= 179\n",
    "        target_tensor.append(slot_vector)\n",
    "        q = ' '.join(map(i2t.get, query[i]))\n",
    "        query_data.append(q.replace('BOS', '').replace('EOS',''))\n",
    "        intent_data.append(i2in[intent[i][0]])\n",
    "        slot = ' '.join(slot_text)\n",
    "        slot_data.append(slot[1:-1])\n",
    "        if i in to_show and verbose:\n",
    "          print('Query text:', q)\n",
    "          print('Query vector: ', query[i])\n",
    "          print('Intent label: ', i2in[intent[i][0]])\n",
    "          print('Slot text: ', slot)\n",
    "          print('Slot vector: ', slot_vector)\n",
    "          print('*'*74)\n",
    "    query_data = np.array(query_data)\n",
    "    intent_data = np.array(intent_data)\n",
    "    slot_data = np.array(slot_data)\n",
    "    intent_data_label = np.array(intent).flatten()\n",
    "    return t2i, s2i, in2i, i2t, i2s, i2in, input_tensor, target_tensor, query_data, intent_data, intent_data_label, slot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  loading:  atis/atis.train.pkl\n",
      "      samples: 4978\n",
      "   vocab_size:  943\n",
      "   slot count:  129\n",
      " intent count:   26\n",
      "Query text: BOS oakland to philadelphia saturday EOS\n",
      "Query vector:  [178 644 851 678 740 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O B-fromloc.city_name O B-toloc.city_name B-depart_date.day_name O\n",
      "Slot vector:  [128, 48, 128, 78, 26, 128]\n",
      "**************************************************************************\n",
      "Query text: BOS now i 'd like to see flights from detroit to st. petersburg on the next tuesday EOS\n",
      "Query vector:  [178 637 479   0 545 851 754 429 444 361 851 789 677 654 827 621 874 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O O O O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O O B-depart_date.date_relative B-depart_date.day_name O\n",
      "Slot vector:  [128, 128, 128, 128, 128, 128, 128, 128, 128, 48, 128, 78, 125, 128, 128, 25, 26, 128]\n",
      "**************************************************************************\n",
      "Query text: BOS i need information for flights leaving baltimore and arriving in atlanta EOS\n",
      "Query vector:  [178 479 617 492 435 429 539 247 215 238 482 242 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O O O O O O O B-fromloc.city_name O O O B-toloc.city_name O\n",
      "Slot vector:  [128, 128, 128, 128, 128, 128, 128, 48, 128, 128, 128, 78, 128]\n",
      "**************************************************************************\n",
      "Query text: BOS what is the round trip fare on continental 1291 from denver to san francisco and return EOS\n",
      "Query vector:  [178 916 498 827 730 870 414 654 325  45 444 351 851 739 440 215 726 179]\n",
      "Intent label:  airfare\n",
      "Slot text:  O O O O B-round_trip I-round_trip O O B-airline_name B-flight_number O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-round_trip O\n",
      "Slot vector:  [128, 128, 128, 128, 66, 119, 128, 128, 2, 43, 128, 48, 128, 78, 125, 128, 66, 128]\n",
      "**************************************************************************\n",
      "Query text: BOS list the flights from san francisco to philadelphia on american airlines EOS\n",
      "Query vector:  [178 549 827 429 444 739 440 851 678 654 212 200 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O O O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name O B-airline_name I-airline_name O\n",
      "Slot vector:  [128, 128, 128, 128, 128, 48, 110, 128, 78, 128, 2, 83, 128]\n",
      "**************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# load ATIS training dataset\n",
    "t2i_train, s2i_train, in2i_train, i2t_train, i2s_train, i2in_train, input_tensor_train, target_tensor_train, query_data_train, intent_data_train, intent_data_label_train, slot_data_train = load_atis('atis.train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  loading:  atis/atis.test.pkl\n",
      "      samples:  893\n",
      "   vocab_size:  943\n",
      "   slot count:  129\n",
      " intent count:   26\n",
      "Query text: BOS monday morning i would like to fly from columbus to indianapolis EOS\n",
      "Query vector:  [178 601 606 479 932 545 851 431 444 312 851 489 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O B-depart_date.day_name B-depart_time.period_of_day O O O O O O B-fromloc.city_name O B-toloc.city_name O\n",
      "Slot vector:  [128, 26, 33, 128, 128, 128, 128, 128, 128, 48, 128, 78, 128]\n",
      "**************************************************************************\n",
      "Query text: BOS find nonstop flights from salt lake city to new york on saturday april ninth EOS\n",
      "Query vector:  [178 423 629 429 444 736 521 301 851 619 937 654 740 227 626 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O O B-flight_stop O O B-fromloc.city_name I-fromloc.city_name I-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_date.day_name B-depart_date.month_name B-depart_date.day_number O\n",
      "Slot vector:  [128, 128, 44, 128, 128, 48, 110, 110, 128, 78, 125, 128, 26, 28, 27, 128]\n",
      "**************************************************************************\n",
      "Query text: BOS what flights leave from cincinnati in the morning and arrive in tampa EOS\n",
      "Query vector:  [178 916 429 537 444 299 482 827 606 215 236 482 816 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O O O O O B-fromloc.city_name O O B-depart_time.period_of_day O O O B-toloc.city_name O\n",
      "Slot vector:  [128, 128, 128, 128, 128, 48, 128, 128, 33, 128, 128, 128, 78, 128]\n",
      "**************************************************************************\n",
      "Query text: BOS list all flights from kansas city to cleveland EOS\n",
      "Query vector:  [178 549 207 429 444 511 301 851 304 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O O O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name O\n",
      "Slot vector:  [128, 128, 128, 128, 128, 48, 110, 128, 78, 128]\n",
      "**************************************************************************\n",
      "Query text: BOS list flights from dallas to houston EOS\n",
      "Query vector:  [178 549 429 444 339 851 476 179]\n",
      "Intent label:  flight\n",
      "Slot text:  O O O O B-fromloc.city_name O B-toloc.city_name O\n",
      "Slot vector:  [128, 128, 128, 128, 48, 128, 78, 128]\n",
      "**************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# load ATIS testing dataset\n",
    "t2i_test, s2i_test, in2i_test, i2t_test, i2s_test, i2in_test, input_tensor_test, target_tensor_test, query_data_test, intent_data_test, intent_data_label_test, slot_data_test = load_atis('atis.test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = intent_data_label_train\n",
    "plt.hist(labels)\n",
    "plt.xlabel('intent')\n",
    "plt.ylabel('nb samples')\n",
    "plt.title('intent distribution')\n",
    "plt.xticks(np.arange(len(np.unique(labels))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giudittaparolini/anaconda3/envs/transformers/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/giudittaparolini/anaconda3/envs/transformers/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/giudittaparolini/anaconda3/envs/transformers/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/giudittaparolini/anaconda3/envs/transformers/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/giudittaparolini/anaconda3/envs/transformers/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/giudittaparolini/anaconda3/envs/transformers/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# BERT imports\n",
    "import torch\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from pytorch_transformers.tokenization_bert import BertTokenizer, BertConfig\n",
    "#from pytorch_transformers.modeling_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]  i want to fly from boston at 838 am and arrive in denver at 1110 in the morning  [SEP]\n",
      "Tokenize the first sentence:\n",
      "['[CLS]', 'i', 'want', 'to', 'fly', 'from', 'boston', 'at', '83', '##8', 'am', 'and', 'arrive', 'in', 'denver', 'at', '111', '##0', 'in', 'the', 'morning', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# add special tokens for BERT to work properly\n",
    "sentences = [\"[CLS] \" + query + \" [SEP]\" for query in query_data_train]\n",
    "print(sentences[0])\n",
    "\n",
    "# Tokenize with BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. \n",
    "MAX_LEN = 128\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)\n",
    "                                             \n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Select a batch size for training. \n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader \n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=labels)\n",
    "#model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /Users/distiller/project/conda/conda-bld/pytorch_1573049308345/work/aten/src/THNN/generic/ClassNLLCriterion.c:97",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e7d69dc5c50f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mtrain_loss_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformers/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /Users/distiller/project/conda/conda-bld/pytorch_1573049308345/work/aten/src/THNN/generic/ClassNLLCriterion.c:97"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "\n",
    "# BERT fine-tuning parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr=2e-5,\n",
    "                     #warmup=.1\n",
    "                 )\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "  \n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "# Number of training epochs \n",
    "epochs = 4\n",
    "\n",
    "# BERT training loop\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "  \n",
    "  ## TRAINING\n",
    "  \n",
    "  # Set our model to training mode\n",
    "  model.train()  \n",
    "  # Tracking variables\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    train_loss_set.append(loss.item())    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "       \n",
    "  ## VALIDATION\n",
    "\n",
    "  # Put model in evaluation mode\n",
    "  model.eval()\n",
    "  # Tracking variables \n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "\n",
    "# plot training performance\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(train_loss_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
